{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpG+ETpLZ1FioQVePx9eRB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhinavDwivediii/Deep-Learning-Lab/blob/main/DL_Exp4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "yY14iFKmNmxs",
        "outputId": "d640f71d-70a4-487d-ad74-6a206b15d1e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== CATS VS DOGS CLASSIFICATION WITH TRANSFER LEARNING ===\n",
            "\n",
            "1. LOADING DATASET...\n",
            "Loading cats images...\n",
            "Loading dogs images...\n",
            "\n",
            "Total images loaded: 0\n",
            "Cats: 0, Dogs: 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3924804064.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cats: {np.sum(y_all == 0)}, Dogs: {np.sum(y_all == 1)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0mX_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2851\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2852\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2482\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Dataset paths\n",
        "cats_dir = 'EXP_4_DATASET/cats_set'\n",
        "dogs_dir = 'EXP_4_DATASET/dogs_set'\n",
        "class_names = ['cats', 'dogs']\n",
        "\n",
        "print(\"=== CATS VS DOGS CLASSIFICATION WITH TRANSFER LEARNING ===\\n\")\n",
        "\n",
        "# 1. DATASET LOADING\n",
        "print(\"1. LOADING DATASET...\")\n",
        "\n",
        "def load_cats_dogs_dataset():\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    print(\"Loading cats images...\")\n",
        "    if os.path.exists(cats_dir):\n",
        "        cat_files = [f for f in os.listdir(cats_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        print(f\"Found {len(cat_files)} cat images\")\n",
        "\n",
        "        for filename in cat_files:\n",
        "            img_path = os.path.join(cats_dir, filename)\n",
        "            try:\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    img = cv2.resize(img, (224, 224))\n",
        "                    images.append(img)\n",
        "                    labels.append(0)\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "    print(\"Loading dogs images...\")\n",
        "    if os.path.exists(dogs_dir):\n",
        "        dog_files = [f for f in os.listdir(dogs_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        print(f\"Found {len(dog_files)} dog images\")\n",
        "\n",
        "        for filename in dog_files:\n",
        "            img_path = os.path.join(dogs_dir, filename)\n",
        "            try:\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    img = cv2.resize(img, (224, 224))\n",
        "                    images.append(img)\n",
        "                    labels.append(1)\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "X_all, y_all = load_cats_dogs_dataset()\n",
        "print(f\"\\nTotal images loaded: {len(X_all)}\")\n",
        "print(f\"Cats: {np.sum(y_all == 0)}, Dogs: {np.sum(y_all == 1)}\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_all, y_all, test_size=0.2, random_state=42, stratify=y_all\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train.shape[0]} images\")\n",
        "print(f\"Test set: {X_test.shape[0]} images\")\n",
        "\n",
        "# 2. EXPLORATORY DATA ANALYSIS AND PREPROCESSING\n",
        "print(\"\\n2. EXPLORATORY DATA ANALYSIS...\")\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "plt.subplot(2, 3, 1)\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "plt.bar([class_names[i] for i in unique], counts, color=['orange', 'blue'])\n",
        "plt.title('Training Set Class Distribution')\n",
        "plt.ylabel('Number of Images')\n",
        "\n",
        "plt.subplot(2, 3, 2)\n",
        "sample_indices = [np.where(y_train == 0)[0][0], np.where(y_train == 1)[0][0]]\n",
        "for i, idx in enumerate(sample_indices):\n",
        "    plt.subplot(2, 3, 3 + i)\n",
        "    plt.imshow(X_train[idx])\n",
        "    plt.title(f'Sample {class_names[i].capitalize()}')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.subplot(2, 3, 5)\n",
        "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "for i in range(8):\n",
        "    class_idx = i % 2\n",
        "    sample_idx = np.where(y_train == class_idx)[0][i//2]\n",
        "    axes[i//4, i%4].imshow(X_train[sample_idx])\n",
        "    axes[i//4, i%4].set_title(class_names[class_idx])\n",
        "    axes[i//4, i%4].axis('off')\n",
        "plt.suptitle('Random Samples from Dataset')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "y_train_categorical = to_categorical(y_train, 2)\n",
        "y_test_categorical = to_categorical(y_test, 2)\n",
        "\n",
        "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
        "    X_train, y_train_categorical, test_size=0.2, random_state=42, stratify=y_train\n",
        ")\n",
        "\n",
        "print(f\"Final training set: {X_train_split.shape}\")\n",
        "print(f\"Validation set: {X_val.shape}\")\n",
        "\n",
        "# 3. BUILDING TRANSFER LEARNING MODEL\n",
        "print(\"\\n3. BUILDING TRANSFER LEARNING MODEL...\")\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dropout(0.5),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"Model Architecture:\")\n",
        "model.summary()\n",
        "\n",
        "# 4. TRAINING THE MODEL\n",
        "print(\"\\n4. TRAINING MODEL...\")\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "print(\"Phase 1: Feature Extraction (10 epochs)\")\n",
        "history1 = model.fit(\n",
        "    datagen.flow(X_train_split, y_train_split, batch_size=32),\n",
        "    epochs=10,\n",
        "    validation_data=(X_val, y_val),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\nPhase 2: Fine-tuning\")\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:100]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"Fine-tuning (10 more epochs)\")\n",
        "history2 = model.fit(\n",
        "    datagen.flow(X_train_split, y_train_split, batch_size=32),\n",
        "    epochs=10,\n",
        "    validation_data=(X_val, y_val),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history_combined = {\n",
        "    'accuracy': history1.history['accuracy'] + history2.history['accuracy'],\n",
        "    'val_accuracy': history1.history['val_accuracy'] + history2.history['val_accuracy'],\n",
        "    'loss': history1.history['loss'] + history2.history['loss'],\n",
        "    'val_loss': history1.history['val_loss'] + history2.history['val_loss']\n",
        "}\n",
        "\n",
        "# 5. MODEL EVALUATION\n",
        "print(\"\\n5. MODEL EVALUATION...\")\n",
        "\n",
        "y_pred_val = model.predict(X_val)\n",
        "y_pred_classes_val = np.argmax(y_pred_val, axis=1)\n",
        "y_true_val = np.argmax(y_val, axis=1)\n",
        "\n",
        "y_pred_test = model.predict(X_test)\n",
        "y_pred_classes_test = np.argmax(y_pred_test, axis=1)\n",
        "\n",
        "accuracy_val = accuracy_score(y_true_val, y_pred_classes_val)\n",
        "precision_val = precision_score(y_true_val, y_pred_classes_val, average='weighted')\n",
        "recall_val = recall_score(y_true_val, y_pred_classes_val, average='weighted')\n",
        "f1_val = f1_score(y_true_val, y_pred_classes_val, average='weighted')\n",
        "\n",
        "accuracy_test = accuracy_score(y_test, y_pred_classes_test)\n",
        "precision_test = precision_score(y_test, y_pred_classes_test, average='weighted')\n",
        "recall_test = recall_score(y_test, y_pred_classes_test, average='weighted')\n",
        "f1_test = f1_score(y_test, y_pred_classes_test, average='weighted')\n",
        "\n",
        "print(\"VALIDATION METRICS:\")\n",
        "print(f\"Accuracy: {accuracy_val:.4f}\")\n",
        "print(f\"Precision: {precision_val:.4f}\")\n",
        "print(f\"Recall: {recall_val:.4f}\")\n",
        "print(f\"F1-Score: {f1_val:.4f}\")\n",
        "\n",
        "print(\"\\nTEST METRICS:\")\n",
        "print(f\"Accuracy: {accuracy_test:.4f}\")\n",
        "print(f\"Precision: {precision_test:.4f}\")\n",
        "print(f\"Recall: {recall_test:.4f}\")\n",
        "print(f\"F1-Score: {f1_test:.4f}\")\n",
        "\n",
        "cm_val = confusion_matrix(y_true_val, y_pred_classes_val)\n",
        "tn, fp, fn, tp = cm_val.ravel()\n",
        "specificity_val = tn / (tn + fp)\n",
        "print(f\"Specificity (Validation): {specificity_val:.4f}\")\n",
        "\n",
        "# 6. VISUALIZATIONS\n",
        "print(\"\\n6. VISUALIZATIONS...\")\n",
        "\n",
        "plt.figure(figsize=(20, 12))\n",
        "\n",
        "plt.subplot(2, 4, 1)\n",
        "plt.plot(history_combined['accuracy'], 'bo-', label='Training Accuracy')\n",
        "plt.plot(history_combined['val_accuracy'], 'ro-', label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.axvline(x=9, color='g', linestyle='--', alpha=0.7, label='Fine-tuning starts')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(2, 4, 2)\n",
        "plt.plot(history_combined['loss'], 'bo-', label='Training Loss')\n",
        "plt.plot(history_combined['val_loss'], 'ro-', label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.axvline(x=9, color='g', linestyle='--', alpha=0.7, label='Fine-tuning starts')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(2, 4, 3)\n",
        "cm_normalized = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
        "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names, cbar_kws={'shrink': 0.8})\n",
        "plt.title('Confusion Matrix (Normalized)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "\n",
        "plt.subplot(2, 4, 4)\n",
        "y_true_bin = label_binarize(y_true_val, classes=[0, 1])\n",
        "y_pred_bin = y_pred_val\n",
        "\n",
        "# âœ… Fixed ROC plotting\n",
        "for i, class_name in enumerate(class_names):\n",
        "    if y_true_bin.shape[1] > i:  # Only plot if class exists\n",
        "        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_bin[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, linewidth=2, label=f'{class_name.capitalize()} (AUC = {roc_auc:.3f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(2, 4, 5)\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "val_scores = [accuracy_val, precision_val, recall_val, f1_val]\n",
        "test_scores = [accuracy_test, precision_test, recall_test, f1_test]\n",
        "\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "plt.bar(x - width/2, val_scores, width, label='Validation', color='lightblue')\n",
        "plt.bar(x + width/2, test_scores, width, label='Test', color='lightcoral')\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Performance Comparison')\n",
        "plt.xticks(x, metrics)\n",
        "plt.legend()\n",
        "plt.ylim(0, 1)\n",
        "for i, (v, t) in enumerate(zip(val_scores, test_scores)):\n",
        "    plt.text(i - width/2, v + 0.01, f'{v:.3f}', ha='center', va='bottom', fontsize=9)\n",
        "    plt.text(i + width/2, t + 0.01, f'{t:.3f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# AUC Scores\n",
        "if y_true_bin.shape[1] == 2:\n",
        "    micro_auc = roc_auc_score(y_true_bin, y_pred_bin, average='micro')\n",
        "    macro_auc = roc_auc_score(y_true_bin, y_pred_bin, average='macro')\n",
        "    print(f\"\\nMicro-average ROC AUC: {micro_auc:.4f}\")\n",
        "    print(f\"Macro-average ROC AUC: {macro_auc:.4f}\")\n",
        "\n",
        "# 7. DETAILED CLASSIFICATION REPORT\n",
        "print(\"\\n7. DETAILED CLASSIFICATION REPORT:\")\n",
        "print(classification_report(y_true_val, y_pred_classes_val, target_names=class_names))\n",
        "\n",
        "print(\"\\nTEST SET CLASSIFICATION REPORT:\")\n",
        "print(classification_report(y_test, y_pred_classes_test, target_names=class_names))\n"
      ]
    }
  ]
}