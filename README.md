# ğŸ“¦ Deep-Learning-Experiments

â”£ ğŸ“‚ Exp_1 Compare TensorFlow, Keras, and PyTorch by implementing linear regression. Analyze code verbosity, API design patterns, and debugging capabilities across frameworks.

â”ƒ â”£ ğŸ““ experiment.ipynb

â”ƒ â”£ ğŸ“‚ datasets

â”ƒ â”— ğŸ“‚ images



â”£ ğŸ“‚ Exp_2 Build neural network components from ground up without high-level libraries. Implement forward propagation, backpropagation, and training mechanisms.

â”ƒ â”£ ğŸ““ experiment.ipynb

â”ƒ â”£ ğŸ“‚ datasets

â”ƒ â”— ğŸ“‚ images



â”£ ğŸ“‚ [Exp_3] End-to-end classification pipeline using deep learning frameworks. Includes data normalization, model building, training curves, and confusion matrix analysis.

â”ƒ â”£ ğŸ““ experiment.ipynb

â”ƒ â”£ ğŸ“‚ datasets

â”ƒ â”— ğŸ“‚ images



â”£ ğŸ“‚ Exp_4 Leverage pretrained models (ResNet, EfficientNet, MobileNet) for image classification. Implement both feature extraction and fine-tuning approaches.

â”ƒ â”£ ğŸ““ experiment.ipynb

â”ƒ â”£ ğŸ“‚ datasets

â”ƒ â”— ğŸ“‚ images



â”£ ğŸ“‚ Exp_5 Deep dive into training mechanisms. Visualize activation functions (Sigmoid, ReLU, Tanh, Softmax) and loss functions. Compare SGD, Momentum, and Adam optimizers.

â”ƒ â”£ ğŸ““ experiment.ipynb

â”ƒ â”£ ğŸ“‚ datasets

â”ƒ â”— ğŸ“‚ images



â”£ ğŸ“‚ Exp_6 Build and train MLP architectures with various configurations. Explore different layer depths, neuron counts, and activation strategies.

â”ƒ â”£ ğŸ““ experiment.ipynb

â”ƒ â”£ ğŸ“‚ datasets

â”ƒ â”— ğŸ“‚ images



â”£ ğŸ“‚ Exp_7 Implement CNN components from scratch. Visualize learned features through feature maps and understand how convolution and pooling operations work.

â”ƒ â”£ ğŸ““ experiment.ipynb

â”ƒ â”£ ğŸ“‚ datasets

â”ƒ â”— ğŸ“‚ images



â”£ ğŸ“‚ Exp_8 Implement CNN with data augmentation strategies to improve model generalization. Apply various image transformations and analyze their impact on classification accuracy.

â”ƒ â”£ ğŸ““ experiment.ipynb

â”ƒ â”£ ğŸ“‚ datasets

â”ƒ â”— ğŸ“‚ images



â”£ ğŸ“‚ Exp_9 Implement CNN-based object detection to identify and localize objects in images. Build detection pipelines with bounding box regression and classification.

â”ƒ â”£ ğŸ““ convolutional-neural-network-cnn-tutorial.ipynb

â”ƒ â”£ ğŸ“‚ test

â”ƒ â”— ğŸ“‚ train



â”£ ğŸ“‚ Exp_10 Introduction to object detection using R-CNN approach. Implement region proposal methods and train detection models on Pascal VOC dataset.

â”ƒ â”£ ğŸ““ Exp10_FasterRCNN_ObjectDetection.ipynb

â”ƒ â”£ ğŸ“‚ Pascal_voc

â”ƒ â”£ ğŸ“„ detection_results.png

â”ƒ â”— ğŸ“„ sample_annotations.png



â”£ ğŸ“‚ Exp_11 Introduction to image segmentation and implement UNet model for pixel-level predictions. Learn encoder-decoder architectures for dense prediction tasks.

â”ƒ â”£ ğŸ““ unet_segmentation.ipynb

â”ƒ â”— ğŸ“„ best_unet_model.pth



â”£ ğŸ“‚ Exp_12 Design standard autoencoder models for image reconstruction and representation learning. Explore latent space representations and dimensionality reduction.

â”ƒ â”£ ğŸ““ Pre_process.ipynb

â”ƒ â”£ ğŸ“„ model.py

â”ƒ â”£ ğŸ“„ autoencoder_celeba.pth

â”ƒ â”£ ğŸ“„ latent_space.png

â”ƒ â”£ ğŸ“„ reconstruction_results.png

â”ƒ â”— ğŸ“„ training_loss.png



â”£ ğŸ“‚ Exp_13 Implement Variational Autoencoders for learning latent distributions and generating novel images. Analyze class-wise latent space representations.

â”ƒ â”£ ğŸ“„ model.py

â”ƒ â”£ ğŸ“„ vae_fashion_mnist.pth

â”ƒ â”£ ğŸ“„ vae_generated_samples.png

â”ƒ â”£ ğŸ“„ vae_interpolation.png

â”ƒ â”£ ğŸ“„ vae_latent_space.png

â”ƒ â”£ ğŸ“„ vae_manifold.png

â”ƒ â”£ ğŸ“„ vae_reconstruction.png

â”ƒ â”— ğŸ“„ vae_training_loss.png



â”£ ğŸ“‚ Exp_14 Develop and train GAN models for creating realistic image samples. Compare generative performance with VAEs in terms of visual fidelity and diversity.

â”ƒ â”— ğŸ“„ model.py

â”— ğŸ“„ README.md


<h1 align="center">Deep Learning Lab</h1>
<p align="center">This lab presents a comprehensive collection of Deep Learning experiments, ranging from basic concepts to advanced applications. Using popular frameworks like TensorFlow and PyTorch, students gain hands-on experience in building and training neural networks. Key components such as activation functions (ReLU, Sigmoid), optimizers (SGD, Adam), and loss functions are explored to understand model performance and optimization.

Experiments use Kaggle datasets to demonstrate practical applications like image classification, object detection, and text analysis. Students also learn techniques like CNNs, RNNs, transfer learning, and hyperparameter tuning, along with evaluation metrics including accuracy, precision, recall, and AUC-ROC. This lab provides a solid foundation in both the theory and practical implementation of deep learning models.</p>

<!-- Table layout (GitHub-safe) -->
<table>
<tr>
<td width="33.5%" valign="top">
  <h3>Experiment 1: Comparative Study of Deep Learning Frameworks</h3>
  
  <b>Topics:</b><br>
â”œâ”€â”€ TensorFlow Implementation <br>
â”œâ”€â”€ Keras Implementation <br>
â”œâ”€â”€ PyTorch Implementation <br>
â””â”€â”€ Framework Comparison
  
  <a href="https://github.com/AbhinavDwivediii/DL_LAB_500121151_ABHINAV_DWIVEDI/blob/main/DL_Exp1.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <b>Dataset:</b> (use synthetic / iris / any small CSV)
</td>

<td width="33.5%" valign="top">
  <h3>Experiment 2: Building Neural Networks from Scratch</h3>

 <b>Topics:</b><br>
â”œâ”€â”€ Single Neuron (AND Gate) <br>
â”œâ”€â”€ Feedforward Network (XOR) <br>
â”œâ”€â”€ MLP with Backpropagation <br>
â””â”€â”€ Activation & Loss Functions

  <a href="https://github.com/AbhinavDwivediii/DL_LAB_500121151_ABHINAV_DWIVEDI/blob/main/DL_Exp2.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://drive.google.com/drive/folders/1HJFzCnNx4SdC9UR_LKa7-P2xKUz8Fp06?usp=drive_link"><b>ğŸ“ DATASET</b></a>
</td>

<td width="33.5%" valign="top">
  <h3>Experiment 3: Classification with DL Frameworks</h3>

<b>Topics:</b><br>
â”œâ”€â”€ Dataset: MNIST/Fashion-MNIST <br>
â”œâ”€â”€ Data Preprocessing <br>
â”œâ”€â”€ Model Training & Validation <br>
â””â”€â”€ Performance Evaluation 

  <a href="https://github.com/AbhinavDwivediii/DL_LAB_500121151_ABHINAV_DWIVEDI/blob/main/DL_Exp3.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://drive.google.com/drive/folders/118MaTGKLMyaXpPgBYVWlM-KWyYa0DA_b?usp=drive_link"><b>ğŸ“ DATASET</b></a>
</td>
</tr>

<tr>
<td width="33%" valign="top">
  <h3>Experiment 4: Transfer Learning for Image Classification</h3>

<b>Topics:</b><br>
â”œâ”€â”€ Pretrained Models <br>
â”œâ”€â”€ Feature Extraction <br>
â”œâ”€â”€ Fine-Tuning Strategies <br>
â””â”€â”€ Cats vs Dogs / CIFAR-10

  <a href="https://github.com/AbhinavDwivediii/DL_LAB_500121151_ABHINAV_DWIVEDI/blob/main/DL_Exp4.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://drive.google.com/drive/folders/1nuBfkQNFDtnJE9527N61rzPJR_hPSxAL?usp=drive_link"><b>ğŸ“ DATASET</b></a>
</td>

<td width="33%" valign="top">
  <h3>Experiment 5: Training Deep Networks (Loss, Backprop & Optimization)</h3>

<b>Topics:</b><br>
â”œâ”€â”€ Activation Functions Visualization <br>
â”œâ”€â”€ Loss Functions Implementation <br>
â”œâ”€â”€ Backpropagation Algorithm <br>
â””â”€â”€ Optimizer Comparison

  <a href="https://github.com/AbhinavDwivediii/DL_LAB_500121151_ABHINAV_DWIVEDI/blob/main/DL_Exp5.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://drive.google.com/drive/folders/1qqk3nwOxXuC7JZLGj-FkJHQOUcg3JhEn?usp=drive_link"><b>ğŸ“ DATASET</b></a>
</td>

<td width="33%" valign="top">
  <h3>Experiment 6: Implementation of MLP</h3>

<b>Topics:</b><br>
â”œâ”€â”€ MLP Architecture Design <br>
â”œâ”€â”€ Layer Configuration <br>
â”œâ”€â”€ Hyperparameter Tuning <br>
â””â”€â”€ Classification Tasks

  <a href="https://github.com/AbhinavDwivediii/DL_LAB_500121151_ABHINAV_DWIVEDI/blob/main/DL_Exp6.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://drive.google.com/drive/folders/1wPi0ayzv74nrS3TQgt9ZD37-ByxF8kfz?usp=drive_link"><b>ğŸ“ DATASET</b></a>
</td>
</tr>

<tr>
<td width="33%" valign="top">
  <h3>Experiment 7: Implementing CNN â€” Convolution, Pooling, Feature Maps</h3>

<b>Topics:</b><br>
â”œâ”€â”€ Convolution Operations <br>
â”œâ”€â”€ Pooling Layers (Max, Average) <br>
â”œâ”€â”€ Feature Map Extraction <br>
â””â”€â”€ CNN Architecture Design 

  <a href="https://github.com/AbhinavDwivediii/DL_LAB_500121151_ABHINAV_DWIVEDI/blob/main/DL_Exp7.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://drive.google.com/drive/folders/1hzq6UM7t5qeuRAvvEkLb7sR-Ky32Tt7O?usp=drive_link"><b>ğŸ“ DATASET</b></a>
</td>

<td width="33%" valign="top">
  <h3>Experiment 8: CNN with Data Augmentation</h3>

 <b>Topics:</b><br>
â”œâ”€â”€ Data Augmentation Techniques <br>
â”œâ”€â”€ Image Transformations (Rotation, Flip, Zoom) <br>
â”œâ”€â”€ CNN Model Training <br>
â””â”€â”€ Performance Comparison with/without Augmentation

  <a href="https://github.com/AbhinavDwivediii/DL_LAB_500121151_ABHINAV_DWIVEDI/blob/main/DL_Exp8.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://drive.google.com/drive/folders/1xQwsFCUmMHiIsYeeT-QX0pMUdW_EYrwO?usp=drive_link"><b>ğŸ“ DATASET</b></a>
</td>

<td width="33%" valign="top">
  <h3>Experiment 9: CNN Object Detection</h3>

  <b>Topics:</b><br>
â”œâ”€â”€ Object Detection Fundamentals <br>
â”œâ”€â”€ CNN Architecture for Detection <br>
â”œâ”€â”€ Bounding Box Prediction <br>
â””â”€â”€ Training & Evaluation

  <a href="https://github.com/AbhinavDwivediii/DL_LAB_500121151_ABHINAV_DWIVEDI/blob/main/DL_Exp9.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://drive.google.com/drive/folders/1De4B6xDq_skp8m5gOIUQ5V9gSa_YX20c?usp=drive_link"><b>ğŸ“ DATASET</b></a>
</td>
</tr>

<tr>
<td width="33%" valign="top">
  <h3>Experiment 10: Intro to Object Detection (R-CNN)</h3>

<b>Topics:</b><br>
â”œâ”€â”€ Region-based CNN (R-CNN) <br>
â”œâ”€â”€ Region Proposal Networks <br>
â”œâ”€â”€ Faster R-CNN Implementation <br>
â””â”€â”€ Pascal VOC Dataset

  <a href="https://github.com/AbhinavDwivediii/DL_LAB_500121151_ABHINAV_DWIVEDI/blob/main/DL_Exp10.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://drive.google.com/drive/folders/1F7GmB_pEIuSRwljuFUWy4CiMzU1ZQGa1?usp=drive_link"><b>ğŸ“ DATASET</b></a>
</td>

<td width="33%" valign="top">
  <h3>Experiment 11: Image Segmentation with UNet</h3>

<b>Topics:</b><br>
â”œâ”€â”€ Semantic Segmentation <br>
â”œâ”€â”€ UNet Architecture <br>
â”œâ”€â”€ Encoder-Decoder Networks <br>
â””â”€â”€ Pixel-wise Classification

  <a href="https://github.com/AbhinavDwivediii/DL_LAB_500121151_ABHINAV_DWIVEDI/blob/main/DL_Exp11.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://www.kaggle.com/api/v1/datasets/download/pushkar007/vaihingendataann?dataset_version_number=1"><b>ğŸ“ DATASET</b></a>
</td>

<td width="33%" valign="top">
  <h3>Experiment 12: Autoencoders for Image Reconstruction</h3>

 <b>Topics:</b><br>
â”œâ”€â”€ Autoencoder Architecture <br>
â”œâ”€â”€ Dimensionality Reduction <br>
â”œâ”€â”€ Feature Compression <br>
â””â”€â”€ Image Reconstruction

  <a href="https://github.com/AbhinavDwivediii/DL_LAB_500121151_ABHINAV_DWIVEDI/blob/main/DL_Exp12.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://drive.google.com/drive/folders/10iflWSc4i78Z2SDtdpkwN4Ab1XUJrvHf?usp=drive_link"><b>ğŸ“ DATASET</b></a>
</td>
</tr>

<tr>
<td width="33%" valign="top">
  <h3>Experiment 13: Variational Autoencoders (VAEs)</h3>

 <b>Topics:</b><br>
â”œâ”€â”€ Probabilistic Modeling <br>
â”œâ”€â”€ Latent Space Distribution <br>
â”œâ”€â”€ VAE Architecture <br>
â””â”€â”€ Novel Image Generation

  <a href="https://github.com/AbhinavDwivediii/DL_LAB_500121151_ABHINAV_DWIVEDI/blob/main/DL_Exp13.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://drive.google.com/drive/folders/1aVWVPN9fC18fc3aM9JjRFOCLH90MLcSJ?usp=drive_link"><b>ğŸ“ DATASET</b></a>
</td>

<td width="33%" valign="top">
  <h3>Experiment 14: Generative Adversarial Networks (GANs)</h3>

 <b>Topics:</b><br>
â”œâ”€â”€ GAN Architecture <br>
â”œâ”€â”€ Generator & Discriminator <br>
â”œâ”€â”€ Adversarial Training <br>
â””â”€â”€ Synthetic Image Generation

  <a href="https://github.com/AbhinavDwivediii/DL_LAB_500121151_ABHINAV_DWIVEDI/blob/main/DL_Exp14.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://drive.google.com/drive/folders/1eaKCYKqI8ZzTxTHHxi5iDvrVUvgS6tze?usp=drive_link"><b>ğŸ“ DATASET</b></a>
</td>


</tr>
</table>

## ğŸ›  Technologies Used

| Framework       | Version | Purpose                     |
|-----------------|---------|-----------------------------|
| ![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange) | 2.x     | Deep Learning Framework    |
| ![Keras](https://img.shields.io/badge/Keras-2.x-red)             | 2.x     | High-level Neural Networks API |
| ![PyTorch](https://img.shields.io/badge/PyTorch-2.x-red)         | 2.x     | Deep Learning Framework    |
| ![NumPy](https://img.shields.io/badge/NumPy-1.x-blue)            | 1.x     | Numerical Computing        |
| ![Pandas](https://img.shields.io/badge/Pandas-2.x-purple)        | 2.x     | Data Manipulation          |
| ![Matplotlib](https://img.shields.io/badge/Matplotlib-3.x-blue)  | 3.x     | Data Visualization         |
| ![Scikit Learn](https://img.shields.io/badge/Scikit_Learn-1.x-orange) | 1.x  | Machine Learning Tools     |


# THANKYOU!
